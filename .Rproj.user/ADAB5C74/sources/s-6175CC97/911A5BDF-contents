# read in data for cluster analysis

seg.raw <- read.csv("http://goo.gl/qw303p")
str(seg.raw)
seg.raw

summary(seg.raw)
seg.df <- seg.raw [ , -7]
summary(seg.df)

seg.summ <- function (data , groups) 
{aggregate (data , list(groups), function (x) mean(as.numeric (x)))}

# recode factor variables to binary data
seg.summ ( seg.df , seg.raw$Segment )
seg.df$ownhome.num<- as.numeric(seg.df$ownHome)
aggregate(seg.df,by=list(seg.raw$Segment),mean,na.rm=TRUE)

seg.df.num<-seg.df
seg.df.num$gender <- ifelse(seg.df$gender=="Male",0,1)
seg.df.num$ownHome <- ifelse(seg.df$ownHome =="ownNo",0 ,1)
seg.df.num$subscribe <- ifelse(seg.df$subscribe =="subNo" ,0 ,1)
summary(seg.df)
summary(seg.df.num)

head(seg.df)
tmp<-dist(seg.df[,-3])
as.matrix(tmp)[1:5,1:5]

tmp<-scale(seg.df.num)
str(tmp)
summary(tmp)

# compute distances
str(seg.df.num)
seg.df.scale<-apply(seg.df.num,2,scale)
t(seg.df.scale)%*%seg.df.scale/299 # check with compution of correlation 
summary(seg.df.scale)
summary(seg.df.num)
str(seg.df.scale)
seg.df.scale<-as.matrix(seg.df.scale)
seg.df.scale.dist <- dist(seg.df.scale) # compute distance on standardized data
as.matrix(seg.df.scale.dist)[1:5,1:5]


?daisy
summary(seg.df)
tmp <- daisy(seg.df)
as.matrix(tmp)[1:5,1:5]

library(cluster)
str(seg.df.num)
seg.dist <- daisy(seg.df.num,stand=TRUE)
str(seg.dist)
as.matrix(seg.dist)[1:5,1:5]

seg.dist <- daisy(seg.df)
str(seg.dist)
as.matrix(seg.dist)[1:5,1:5]

seg.dist <- dist(seg.df.num)
str(seg.dist)
as.matrix(seg.dist)[1:5,1:5]


# hierachical clustering with distances from daisy
?daisy
seg.hc <- hclust (seg.dist , method ="single")
?hclust
str(seg.hc)
plot(seg.hc)
seg.hc
summary(seg.hc)
plot(cut(as.dendrogram(seg.hc), h =0.5)$lower[[1]])
plot(rev(seg.hc$height^2))
plot(rev(seg.hc$height^2)[1:50], type="b")
seg.df[c(101 , 107) , ]

seg.hc.segment <- cutree(seg.hc, k=4)
str(seg.hc.segment)
table(seg.hc.segment)
seg.df$single4<-seg.hc.segment
str(seg.df)


seg.summ ( seg.df , seg.df$single4 )
summary(seg.df)

# hierachical clustering with distances from standardized data and Euclidean

seg.hc <- hclust (seg.df.scale.dist , method ="single")
plot(seg.hc)
plot(cut(as.dendrogram(seg.hc), h =0.5)$lower[[1]])
plot(rev(seg.hc$height^2))
plot(rev(seg.hc$height^2)[1:50], type="b")
seg.df[c(101 , 107) , ]

seg.hc.segment <- cutree(seg.hc, k=4)
str(seg.hc.segment)
seg.df.scale.dist$single4<-seg.hc.segment
str(seg.df)



# interpret cluster solution
cor(cophenetic(seg.hc), seg.dist )
plot(seg.hc)
rect.hclust(seg.hc, k=9, border ="red")
seg.hc.segment <- cutree(seg.hc, k=4)
table(seg.hc.segment )

str(seg.hc.segment)
seg.summ(seg.df,seg.hc.segment )

plot(jitter(as.numeric(seg.df$gender)) ~
       jitter(as.numeric(seg.df$ subscribe)),
     col= seg.hc.segment,yaxt="n", xaxt ="n", ylab ="", xlab="")
axis(1, at=c(1,2),labels=c(" Subscribe : No","Subscribe:Yes"))
axis(2, at=c(1,2),labels=levels(seg.df$gender))





# k-Means
set.seed (1) 
seg.k <- kmeans(seg.df.num , centers =10)
str(seg.k)
seg.k
seg.summ (seg.df , seg.k$cluster )

seg.k$betweenss
seg.k$totss
seg.k$betweenss/seg.k$totss
set.seed (987) 
seg.k <- kmeans(seg.df.num , centers =10)
seg.k$betweenss

t<-kmeans(tnw[,2:10],centers=4)
t

ss.all<-data.frame(i=1:10000,fit=0)
head(ss.all)
for(i in 1:10000){
set.seed(i+100)
tmp <- kmeans(seg.df.num , centers =4)
ss.all[ss.all$i==i,]$fit<-tmp$betweenss
}
str(ss.all)
ss.all[which.max(ss.all$fit), ]
ss.all[1:10,]
seg.k <- kmeans(seg.df.num , centers =4)
seg.k
seg.summ (seg.df , seg.k$cluster )
set.seed (102) 
seg.k <- kmeans(seg.df.num , centers =4)
seg.summ (seg.df , seg.k$cluster )
boxplot(seg.df.num$income~seg.k$cluster ,
         xlab ="Income", ylab ="Segment",
         horizontal = TRUE )
library ( cluster )
clusplot(seg.df , seg.k$cluster , color =TRUE , shade =TRUE ,
          labels =4, lines =0, main ="K- means cluster plot ")


# Model based clustering
#install.packages('mclust')
library(mclust)
seg.mc <- Mclust(seg.df.num) 
seg.mc
summary(seg.mc)
seg.mc4 <- Mclust(seg.df.num , G=4) # 4 clusters
summary(seg.mc4)
seg.summ(seg.df,seg.mc$class)
seg.summ(seg.df,seg.mc4$class)

clusplot(seg.df,seg.mc$class,color=TRUE,shade=TRUE ,
         labels =4, lines =0, main ="Model-based cluster plot ")
clusplot(seg.df,seg.mc4$class,color=TRUE,shade=TRUE ,
         labels =4, lines =0, main ="Model-based cluster plot ")

seg.mc <- Mclust(ice) 
clusplot(ice,seg.mc$class,color=TRUE,shade=TRUE ,
         labels =4, lines =0, main ="Model-based cluster plot ")


# NOW OUR CITY TRIPS DATA

setwd('C:/Users/klapperd/Dropbox/Humboldt/Lehre/CACI/WS1920/Data')
library(plyr)
data<-read.csv("QuestionaireData_CityTrips_csv.csv")
dat<-read.csv("data.cities.long.csv")
head(dat)
nrow(dat)
attribute.dissagg <- na.omit(dat)
tmp<-attribute.dissagg$City
attribute<-cbind(tmp,attribute.dissagg[1:20])
attribute <- rename(attribute, replace = c("tmp" = "City"))
attribute <- rename(attribute, replace = c("V1" = "friendly"))
attribute <- rename(attribute, replace = c("V2" = "historical"))
attribute <- rename(attribute, replace = c("V3" = "affordable"))
attribute <- rename(attribute, replace = c("V4" = "trendy"))
attribute <- rename(attribute, replace = c("V5" = "vibrant"))
attribute <- rename(attribute, replace = c("V6" = "delifood"))
attribute <- rename(attribute, replace = c("V7" = "easyaround"))
attribute <- rename(attribute, replace = c("V8" = "shopping"))
attribute <- rename(attribute, replace = c("V9" = "culturalevents"))
attribute <- rename(attribute, replace = c("V10" = "museum"))
attribute <- rename(attribute, replace = c("V11" = "clean"))
attribute <- rename(attribute, replace = c("V12" = "green"))
attribute <- rename(attribute, replace = c("V13" = "multicultural"))
attribute <- rename(attribute, replace = c("V14" = "tootouristic"))
attribute <- rename(attribute, replace = c("V15" = "fun"))
attribute <- rename(attribute, replace = c("V16" = "noisy"))
attribute <- rename(attribute, replace = c("V17" = "romantic"))
attribute <- rename(attribute, replace = c("V18" = "safe"))
attribute <- rename(attribute, replace = c("V19" = "beautiful"))
attribute <- rename(attribute, replace = c("V20" = "Englishspeaking"))
str(attribute)
eigen(cor(attribute[,2:21]))$values

plot(eigen(cor(attribute[,2:21]))$values)






# PCA and Factor analysis with easy to do R-FUNCTIONS
library(GPArotation)
library(psych)
a.pca<-principal(attribute[,2:21],nfactors=4, rotate ="varimax")
a.pca
head(a.pca$scores)
head(attribute)
aggregate(a.pca$scores, by=list(attribute$City),mean, na.rm=TRUE) # compute aggregate component score for cities
t(a.pca$scores)%*%a.pca$scores/(nrow(attribute[,2:21])-1) # show taht factors are uncorrelated


# factor analysis
a.fa<-fa(attribute[,2:21],method=mle,scores='tenBerge', nfactors=4, rotate ="varimax")
a.fa
aggregate(a.fa$scores, by=list(attribute$City),mean, na.rm=TRUE) # compute aggregate component score for cities
t(a.fa$scores)%*%a.fa$scores/(nrow(attribute[,2:21])-1) # show taht factors are uncorrelated

str(attribute)
n.scores<-aggregate(a.fa$scores, by=list(attribute.dissagg$Sample,attribute.dissagg$ID),sum, na.rm=TRUE) # compute aggregate component score for cities
a.fa$scores
nrow(attribute.dissagg)
nrow(a.fa$scores)
nrow(n.scores)
head(n.scores,50)
n.scores[c(72,82),]
n.scores<-n.scores[-72,]
n.scores.dist<-dist(n.scores[,3:6])
fit <- isoMDS(n.scores.dist, k = 2)
fit
x <- fit$points[,1]
y <- fit$points[,2]
plot(x, y, xlab = "Coordinate 1", ylab = "Coordinate 2", main = "Metric MDS", 
     pch = 19, )

plot(x, y, xlab = "Coordinate 1", ylab = "Coordinate 2", main = "Metric MDS", 
     pch = 19, 
#ylim = c(-5.5, 5.5), xlim = c(-25.5, 25.5)
)
abline(h = 0, v = 0, col = "grey")

n.scores.clust <- hclust(n.scores.dist, method ="single")
plot(n.scores.clust)
n.scores.clust <- hclust(n.scores.dist, method ="ward.D2")




# now cluster person on general questions
n.dist<-dist(data[-72,3:22])
as.matrix(n.dist,10,10)
fit <- isoMDS(n.dist, k = 2)
fit
x <- fit$points[,1]
y <- fit$points[,2]
plot(x, y, xlab = "Coordinate 1", ylab = "Coordinate 2", main = "Metric MDS", 
     pch = 19, 
     #ylim = c(-5.5, 5.5), xlim = c(-25.5, 25.5)
)
abline(h = 0, v = 0, col = "grey")

n.clust <- hclust(n.dist, method ="single")
plot(n.clust)
n.clust <- hclust(n.dist, method ="ward.D2")
plot(n.clust)





n.clust.segment <- cutree(n.clust, k=4)
str(n.clust.segment)
table(n.clust.segment)
seg.summ(data[-72,3:22],n.clust.segment)

plot(rev(n.clust$height^2))
plot(rev(n.clust$height^2)[1:50], type="b")


set.seed (1) 
seg.k <- kmeans(n.dist , centers =4)
seg.summ (data[-72,3:22],seg.k$cluster )




# Cluster Persons from bluetooth speaker questionaire

bluetooth<-read.csv("indivData.csv")
head(bluetooth)
str(bluetooth)
summary(bluetooth)
bluetooth.dist<-dist(apply(bluetooth[,13:26],2,scale)) # one set of variables selected
str(bluetooth.dist)
as.matrix(bluetooth.dist)[1:5,1:5]
library(MASS)
fit <- isoMDS(bluetooth.dist, k = 2)
fit
x <- fit$points[,1]
y <- fit$points[,2]
plot(x, y, xlab = "Coordinate 1", ylab = "Coordinate 2", main = "Metric MDS", 
     pch = 19, ylim = c(-5.5, 5.5), xlim = c(-5.5, 5.5))
plot(x, y, xlab = "Coordinate 1", ylab = "Coordinate 2", main = "Metric MDS", 
     pch = 19, )
text(x, y, labels = bluetooth$id, cex = 1, pos = 4)
abline(h = 0, v = 0, col = "grey")

bluetoothclust <- hclust(bluetooth.dist, method ="single")
plot(bluetoothclust)
bluetoothclust <- hclust(bluetooth.dist, method ="ward.D2")
plot(bluetoothclust)

summary(bluetooth)
bluetoothclust.segment <- cutree(bluetoothclust, k=4)
str(bluetoothclust.segment)


table(bluetoothclust.segment)

seg.summ(bluetooth,bluetoothclust.segment)


plot(rev(bluetoothclust$height^2))
plot(rev(bluetoothclust$height^2)[1:50], type="b")


set.seed (1) 
seg.k <- kmeans(bluetooth.dist , centers =4)
seg.summ (bluetooth,seg.k$cluster )

